import 'dart:async';
import 'dart:io';
import 'package:file_picker/file_picker.dart';
import 'package:lawyer_app/app/common/extension/string_extension.dart';
import 'package:lawyer_app/app/http/apis.dart';
import 'package:lawyer_app/app/http/net/net_utils.dart';
import 'package:lawyer_app/app/http/net/tool/error_handle.dart';
import 'package:lawyer_app/app/modules/chatPage/views/widgets/chat_bottom_panel.dart';
import 'package:lawyer_app/app/utils/object_utils.dart';
import 'package:path_provider/path_provider.dart';

import 'package:chat_bottom_container/chat_bottom_container.dart';
import 'package:flutter/material.dart';
import 'package:get/get.dart';
import 'package:lawyer_app/app/http/net/tool/logger.dart';
import 'package:lawyer_app/app/utils/permission_util.dart';
import 'package:lawyer_app/app/utils/toast_utils.dart';
import 'package:record/record.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:uuid/uuid.dart';
import 'package:vibration/vibration.dart';

import '../../../http/net/sse_utils.dart';
import '../../../utils/image_picker_util.dart';
import '../models/chat_agent_ui_config.dart';

class UiMessage {
  UiMessage({
    required this.id,
    required this.text,
    required this.isAi,
    required this.createdAt,
    this.hasAnimated = false,
    this.thinkingProcess,
    this.deepThinkingProcess,
    this.thinkingSeconds,
  });

  final String id;
  final String text;
  final bool isAi;
  final DateTime createdAt;
  final bool hasAnimated;
  final String? thinkingProcess; // æ€è€ƒè¿‡ç¨‹å†…å®¹
  final String? deepThinkingProcess; // æ·±åº¦æ€è€ƒè¿‡ç¨‹å†…å®¹
  final int? thinkingSeconds; // æ€è€ƒç”¨æ—¶

  UiMessage copyWith({
    bool? hasAnimated,
    String? thinkingProcess,
    String? deepThinkingProcess,
    int? thinkingSeconds,
  }) => UiMessage(
    id: id,
    text: text,
    isAi: isAi,
    createdAt: createdAt,
    hasAnimated: hasAnimated ?? this.hasAnimated,
    thinkingProcess: thinkingProcess ?? this.thinkingProcess,
    deepThinkingProcess: deepThinkingProcess ?? this.deepThinkingProcess,
    thinkingSeconds: thinkingSeconds ?? this.thinkingSeconds,
  );
}

enum ChatPanelType { none, keyboard, tool }

class ChatPageController extends GetxController {
  final TextEditingController textController = TextEditingController();
  final FocusNode inputFocusNode = FocusNode();
  final ChatBottomPanelContainerController<ChatPanelType> panelController =
      ChatBottomPanelContainerController<ChatPanelType>();
  final ScrollController scrollController = ScrollController();

  final RxList<UiMessage> messages = <UiMessage>[].obs;
  final RxBool hasText = false.obs;
  final RxBool hasVoice = false.obs;
  final RxBool isRecording = false.obs;
  final RxBool isCancelMode = false.obs;
  final RxDouble recordingAmplitude = 0.0.obs;
  final RxString recognizedText = ''.obs;
  ChatPanelType currentPanelType = ChatPanelType.none;

  final AudioRecorder _audioRecorder = AudioRecorder();
  final stt.SpeechToText _speechToText = stt.SpeechToText();
  String? _recordingPath;
  Offset? _recordingStartPosition;
  StreamSubscription<Amplitude>? _amplitudeSubscription;

  ///èŠå¤©æ™ºèƒ½ä½“id
  String? agentId;
  ///èŠå¤©id
  String? sessionId;

  // å½“å‰æ¶ˆæ¯å†…å®¹
  final RxString currentMessage = ''.obs;

  // åŠ è½½çŠ¶æ€
  final RxBool isLoading = false.obs;

  // SSE è®¢é˜…
  StreamSubscription<SSEEvent>? _sseSubscription;

  void updatePanelType(ChatPanelType type) {
    final targetPanelType = _toBottomPanel(type);
    final targetFocus = _toHandleFocus(type);

    void update() {
      panelController.updatePanelType(
        targetPanelType,
        data: type,
        forceHandleFocus: targetFocus,
      );
    }

    final requiresUnfocusFirst =
        type == ChatPanelType.tool && inputFocusNode.hasFocus;
    if (requiresUnfocusFirst) {
      inputFocusNode.unfocus();
      WidgetsBinding.instance.addPostFrameCallback((_) => update());
    } else {
      update();
    }
  }

  void _handleTextChanged() {
    hasText.value = textController.text.trim().isNotEmpty;
  }

  void handleSendPressed({bool isFocus = true}) {
    final text = textController.text.trim();
    if (text.isEmpty) return;
    _addUserMessage(text);
    textController.clear();
    hasText.value = false;
    if (isFocus) {
      inputFocusNode.requestFocus();
    }
    // å·²ç»åœ¨ _addUserMessage ä¸­è°ƒç”¨ SSEï¼Œä¸éœ€è¦å†è°ƒç”¨ _simulateAiReply
    _scheduleScrollToBottom();
  }

  void handleInputTap() {
    updatePanelType(ChatPanelType.keyboard);
  }

  void handleInputPointerUp() {
    if (inputFocusNode.canRequestFocus && !inputFocusNode.hasFocus) {
      updatePanelType(ChatPanelType.keyboard);
    }
  }

  void handleToolBtnClick() {
    final isToolOpen = currentPanelType == ChatPanelType.tool;
    updatePanelType(isToolOpen ? ChatPanelType.keyboard : ChatPanelType.tool);
  }

  void onPanelTypeChange(ChatBottomPanelType panelType, ChatPanelType? data) {
    switch (panelType) {
      case ChatBottomPanelType.none:
        currentPanelType = ChatPanelType.none;
        break;
      case ChatBottomPanelType.keyboard:
        currentPanelType = ChatPanelType.keyboard;
        break;
      case ChatBottomPanelType.other:
        if (data == null) {
          currentPanelType = ChatPanelType.none;
          break;
        }
        currentPanelType = data;
        break;
    }
  }

  void hidePanel() {
    if (inputFocusNode.hasFocus) {
      inputFocusNode.unfocus();
    }
    if (panelController.currentPanelType != ChatBottomPanelType.none) {
      panelController.updatePanelType(ChatBottomPanelType.none);
    }
  }

  ChatBottomPanelType _toBottomPanel(ChatPanelType type) {
    switch (type) {
      case ChatPanelType.none:
        return ChatBottomPanelType.none;
      case ChatPanelType.keyboard:
        return ChatBottomPanelType.keyboard;
      case ChatPanelType.tool:
        return ChatBottomPanelType.other;
    }
  }

  ChatBottomHandleFocus _toHandleFocus(ChatPanelType type) {
    switch (type) {
      case ChatPanelType.keyboard:
        return ChatBottomHandleFocus.requestFocus;
      case ChatPanelType.tool:
      case ChatPanelType.none:
        return ChatBottomHandleFocus.none;
    }
  }

  ///æ·»åŠ æ¬¢è¿å¼€åœºç™½
  void _addAiWelcome(ChatAgentUiConfig model) {
    messages.add(
      UiMessage(
        id: model.id.toString(),
        text: model.prologue ?? 'æ‚¨å¥½ï¼Œæˆ‘æ˜¯ AI åŠ©æ‰‹ï¼Œéšæ—¶ä¸ºæ‚¨æä¾›æ³•å¾‹ç›¸å…³å’¨è¯¢ã€‚',
        isAi: true,
        createdAt: DateTime.now(),
      ),
    );
    _scheduleScrollToBottom(animated: false);
  }


  ///æ·»åŠ å‘é€æ¶ˆæ¯
  Future<void> _addUserMessage(String text) async {
    if (ObjectUtils.isEmptyString(agentId)) {
      return;
    }
    if (ObjectUtils.isEmptyString(sessionId)) {
      var result = await NetUtils.post(
        Apis.createChatId,
        params: {'agentId': agentId, 'subject': text},
        isLoading: false,
      );
      if (result.code == NetCodeHandle.success) {
        sessionId = result.data.toString();
      }
    }

    if (!ObjectUtils.isEmptyString(sessionId)) {
      messages.add(
        UiMessage(
          id: 'user-${DateTime.now().microsecondsSinceEpoch}',
          text: text,
          isAi: false,
          createdAt: DateTime.now(),
        ),
      );

      _scheduleScrollToBottom();
      
      // ä½¿ç”¨çœŸå®çš„ SSE è¿æ¥æ›¿ä»£æ¨¡æ‹Ÿå›å¤
      _sendMessageWithSSE(text, sessionId!);
    }
  }

  /// ä½¿ç”¨ SSE å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶ AI å›å¤
  Future<void> _sendMessageWithSSE(String message, String sessionId) async {
    // å–æ¶ˆä¹‹å‰çš„è¿æ¥
    cancelConnection();

    isLoading.value = true;
    currentMessage.value = '';
    
    // ç”¨äºç´¯ç§¯æ€è€ƒè¿‡ç¨‹å’Œå›å¤å†…å®¹
    String thinkingContent = '';
    String replyContent = '';
    final startTime = DateTime.now();

    // åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ AI æ¶ˆæ¯ç”¨äºæ˜¾ç¤ºå®æ—¶å›å¤
    final aiMessageId = 'ai-${DateTime.now().microsecondsSinceEpoch}';

    // ç”Ÿæˆå”¯ä¸€çš„è¯·æ±‚ ID
    final requestId = const Uuid().v4();

    final request = SSEChatRequest(
      message: message,
      requestId: requestId,
      hisId: sessionId.toNullInt(),
      think: true,
    );

    logPrint('å‘é€æ¶ˆæ¯: $message');

    try {
      _sseSubscription = await SSEUtils().chatStream(
        agentId: agentId!,
        request: request,
        onMessage: (data) {
          // ç´¯ç§¯æ€è€ƒè¿‡ç¨‹ï¼ˆreasoningContentï¼‰
          if (data.reasoningContent != null && data.reasoningContent!.isNotEmpty) {
            thinkingContent += data.reasoningContent!;
            logPrint('âœ… æ”¶åˆ°æ€è€ƒå†…å®¹: ${data.reasoningContent}');
            logPrint('ğŸ“Š ç´¯ç§¯æ€è€ƒå†…å®¹: $thinkingContent');
          }
          
          // ç´¯ç§¯å›å¤å†…å®¹ï¼ˆcontentï¼‰
          if (data.content != null && data.content!.isNotEmpty) {
            replyContent += data.content!;
            logPrint('âœ… æ”¶åˆ°å›å¤å†…å®¹: ${data.content}');
            logPrint('ğŸ“Š ç´¯ç§¯å›å¤å†…å®¹: $replyContent');
          }

          // ç§»é™¤"æ€è€ƒä¸­"æ¶ˆæ¯ï¼ˆåªç§»é™¤ä¸€æ¬¡ï¼‰
          messages.removeWhere((e) => e.id == 'think_id');

          // åˆ›å»ºæ›´æ–°çš„æ¶ˆæ¯
          final aiMessage = UiMessage(
            id: aiMessageId,
            text: '',
            isAi: true,
            createdAt: DateTime.now(),
            thinkingProcess: thinkingContent.isNotEmpty ? thinkingContent : null,
            thinkingSeconds: 3
          );

          // æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨è¯¥æ¶ˆæ¯
          final existingIndex = messages.indexWhere((m) => m.id == aiMessageId);
          if (existingIndex != -1) {
            // æ›´æ–°ç°æœ‰æ¶ˆæ¯
            messages[existingIndex] = aiMessage;
            logPrint('ğŸ”„ æ›´æ–°æ¶ˆæ¯ - æ€è€ƒ: ${thinkingContent.length} å­—ç¬¦, å›å¤: ${replyContent.length} å­—ç¬¦');
          } else {
            // æ·»åŠ æ–°æ¶ˆæ¯
            messages.add(aiMessage);
            logPrint('â• æ·»åŠ æ–°æ¶ˆæ¯ - æ€è€ƒ: ${thinkingContent.length} å­—ç¬¦, å›å¤: ${replyContent.length} å­—ç¬¦');
          }
          
          // è§¦å‘æ»šåŠ¨
          scheduleScrollDuringTyping();
        },
        onError: (error) {
          logPrint('SSE é”™è¯¯: $error');
          showToast('è¿æ¥å¤±è´¥: $error');
          isLoading.value = false;
          
          // æ›´æ–°æ¶ˆæ¯ä¸ºé”™è¯¯çŠ¶æ€
          final index = messages.indexWhere((m) => m.id == aiMessageId);
          if (index != -1) {
            messages[index] = UiMessage(
              id: aiMessageId,
              text: 'æŠ±æ­‰ï¼Œè¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
              isAi: true,
              createdAt: messages[index].createdAt,
            );
          }
        },
        onDone: () {
          // è®¡ç®—æ€è€ƒç”¨æ—¶ï¼ˆç§’ï¼‰
          final thinkingSeconds = DateTime.now().difference(startTime).inSeconds;
          
          logPrint('âœ… æ¶ˆæ¯æ¥æ”¶å®Œæˆ');
          logPrint('ğŸ“Š æœ€ç»ˆæ€è€ƒè¿‡ç¨‹: $thinkingContent (${thinkingContent.length} å­—ç¬¦)');
          logPrint('ğŸ“Š æœ€ç»ˆå›å¤å†…å®¹: $replyContent (${replyContent.length} å­—ç¬¦)');
          logPrint('â±ï¸ æ€è€ƒç”¨æ—¶: $thinkingSeconds ç§’');
          isLoading.value = false;
          
          // ç§»é™¤"æ€è€ƒä¸­"æ¶ˆæ¯ï¼ˆç¡®ä¿æ¸…ç†ï¼‰
          messages.removeWhere((e) => e.id == 'think_id');
          
          // æœ€ç»ˆæ›´æ–°æ¶ˆæ¯ï¼ŒåŒ…å«å®Œæ•´çš„æ€è€ƒè¿‡ç¨‹å’Œç”¨æ—¶
          final index = messages.indexWhere((m) => m.id == aiMessageId);
          if (index != -1) {
            messages[index] = UiMessage(
              id: aiMessageId,
              text: replyContent.isNotEmpty ? replyContent : 'æœªæ”¶åˆ°å›å¤å†…å®¹',
              isAi: true,
              createdAt: messages[index].createdAt,
              hasAnimated: false, // è®¾ç½®ä¸º false ä»¥è§¦å‘æ‰“å­—åŠ¨ç”»
              thinkingProcess: thinkingContent.isNotEmpty ? thinkingContent : null,
              deepThinkingProcess: null, // å¦‚æœéœ€è¦åŒºåˆ†æ·±åº¦æ€è€ƒï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè®¾ç½®
              thinkingSeconds: thinkingSeconds,
            );
            logPrint('ğŸ¯ æœ€ç»ˆæ¶ˆæ¯å·²æ›´æ–°');
          } else {
            logPrint('âš ï¸ æœªæ‰¾åˆ°æ¶ˆæ¯ ID: $aiMessageId');
          }
          
          _scheduleScrollToBottom();
        },
      );
    } catch (e) {
      logPrint('å‘é€æ¶ˆæ¯å¤±è´¥: $e');
      showToast('å‘é€å¤±è´¥: $e');
      isLoading.value = false;
      
      // æ›´æ–°æ¶ˆæ¯ä¸ºé”™è¯¯çŠ¶æ€
      final index = messages.indexWhere((m) => m.id == aiMessageId);
      if (index != -1) {
        messages[index] = UiMessage(
          id: aiMessageId,
          text: 'æŠ±æ­‰ï¼Œå‘é€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
          isAi: true,
          createdAt: messages[index].createdAt,
        );
      }
    }
  }

  /// å‘é€æ–‡æœ¬æ¶ˆæ¯ï¼ˆå·²åºŸå¼ƒï¼Œä½¿ç”¨ _sendMessageWithSSE æ›¿ä»£ï¼‰
  @Deprecated('ä½¿ç”¨ _sendMessageWithSSE æ›¿ä»£')
  Future<void> sendTextMessage(String message, String sessionId) async {
    // æ­¤æ–¹æ³•å·²è¢« _sendMessageWithSSE æ›¿ä»£
  }

  void markMessageAnimated(String id) {
    final index = messages.indexWhere((m) => m.id == id);
    if (index == -1) return;
    final current = messages[index];
    if (current.hasAnimated) return;
    messages[index] = current.copyWith(hasAnimated: true);
  }

  void _scrollToBottom({bool animated = true}) {
    if (!scrollController.hasClients) return;
    final position = scrollController.position.maxScrollExtent;
    if (animated) {
      scrollController.animateTo(
        position,
        duration: const Duration(milliseconds: 220),
        curve: Curves.easeOut,
      );
    } else {
      scrollController.jumpTo(position);
    }
  }

  void _scheduleScrollToBottom({
    bool animated = true,
    Duration delay = Duration.zero,
  }) {
    void run() {
      if (isClosed) return;
      WidgetsBinding.instance.addPostFrameCallback((_) {
        if (!isClosed) {
          _scrollToBottom(animated: animated);
        }
      });
    }

    if (delay == Duration.zero) {
      run();
    } else {
      Future.delayed(delay, () {
        if (!isClosed) {
          run();
        }
      });
    }
  }

  void scheduleScrollDuringTyping() {
    if (isClosed) return;
    WidgetsBinding.instance.addPostFrameCallback((_) {
      if (!isClosed) {
        _scrollToBottom(animated: false);
      }
    });
  }

  void handleInputSizeChanged(Size _) {
    _scheduleScrollToBottom(animated: false);
  }

  void _handleFocusChange() {
    if (inputFocusNode.hasFocus) {
      _scheduleScrollToBottom(
        animated: false,
        delay: const Duration(milliseconds: 400),
      );
    }
  }

  @override
  void onInit() {
    super.onInit();
    textController.addListener(_handleTextChanged);
    inputFocusNode.addListener(_handleFocusChange);
    getSystemConfig();
  }

  @override
  void onClose() {
    textController.removeListener(_handleTextChanged);
    inputFocusNode.removeListener(_handleFocusChange);
    _stopAmplitudeListener();
    if (_speechToText.isListening) {
      _speechToText.stop();
    }
    if (isRecording.value) {
      _audioRecorder.stop().catchError((e) {
        logPrint('åœæ­¢å½•éŸ³å¤±è´¥: $e');
        return '';
      });
    }
    textController.dispose();
    inputFocusNode.dispose();
    scrollController.dispose();
    _audioRecorder.dispose();
    if (_recordingPath != null) {
      final file = File(_recordingPath!);
      file.exists().then((exists) {
        if (exists) {
          file.delete().catchError((e) {
            logPrint('åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: $e');
            return file;
          });
        }
      });
    }
    cancelConnection();
    super.onClose();
  }

  Future<void> handleVoicePressed() async {
    bool isAuth = false;
    if (Platform.isIOS) {
      bool isMicAuth = await PermissionUtils.requestMicrophonePermission();
      if (isMicAuth) {
        isAuth = await PermissionUtils.requestSpeechPermission();
      }
    } else {
      isAuth = await PermissionUtils.requestMicrophonePermission();
    }
    if (isAuth) {
      hasVoice.value = !hasVoice.value;
      updatePanelType(
        hasVoice.value ? ChatPanelType.none : ChatPanelType.keyboard,
      );
      if (!hasVoice.value) {
        inputFocusNode.requestFocus();
        _scheduleScrollToBottom();
      }
    }
  }

  Future<void> startRecording(Offset startPosition) async {
    // é˜²æ­¢é‡å¤è§¦å‘
    if (isRecording.value) return;

    // éœ‡åŠ¨åé¦ˆ - ä¸ä½¿ç”¨ awaitï¼Œç›´æ¥è§¦å‘
    if (await Vibration.hasVibrator()) {
      Vibration.vibrate(duration: 50);
    }

    // å…ˆæ˜¾ç¤ºå½•éŸ³ UI
    _recordingStartPosition = startPosition;
    isRecording.value = true;
    isCancelMode.value = false;
    recognizedText.value = '';

    try {
      if (await _audioRecorder.hasPermission()) {
        final directory = await getTemporaryDirectory();
        _recordingPath =
            '${directory.path}/recording_${DateTime.now().millisecondsSinceEpoch}.m4a';

        await _audioRecorder.start(
          const RecordConfig(
            encoder: AudioEncoder.aacLc,
            bitRate: 128000,
            sampleRate: 44100,
          ),
          path: _recordingPath!,
        );

        _startAmplitudeListener();
        _startSpeechRecognition();
      } else {
        isRecording.value = false;
      }
    } catch (e) {
      logPrint('å¼€å§‹å½•éŸ³å¤±è´¥: $e');
      isRecording.value = false;
    }
  }

  Future<void> stopRecording() async {
    if (!isRecording.value) return;

    try {
      final path = await _audioRecorder.stop();
      isRecording.value = false;
      _stopAmplitudeListener();
      await _stopSpeechRecognition();

      if (path != null && !isCancelMode.value) {
        final textToSend = recognizedText.value.trim();
        if (textToSend.isNotEmpty) {
          _addUserMessage(textToSend);
          // å·²ç»åœ¨ _addUserMessage ä¸­è°ƒç”¨ SSEï¼Œä¸éœ€è¦å†è°ƒç”¨ _simulateAiReply
          _scheduleScrollToBottom();
        } else {
          // showToast('æœªè¯†åˆ«åˆ°ä»»ä½•å†…å®¹');
          final file = File(_recordingPath!);
          if (await file.exists()) {
            await file.delete();
          }
        }
      } else if (_recordingPath != null && isCancelMode.value) {
        final file = File(_recordingPath!);
        if (await file.exists()) {
          await file.delete();
        }
      }
    } catch (e) {
      logPrint('åœæ­¢å½•éŸ³å¤±è´¥: $e');
    }

    isCancelMode.value = false;
    recognizedText.value = '';
  }

  Future<void> cancelRecording() async {
    if (!isRecording.value) return;

    try {
      await _audioRecorder.stop();
      isRecording.value = false;
      isCancelMode.value = false;
      _stopAmplitudeListener();
      await _stopSpeechRecognition();

      if (_recordingPath != null) {
        final file = File(_recordingPath!);
        if (await file.exists()) {
          await file.delete();
        }
      }
    } catch (e) {
      logPrint('å–æ¶ˆå½•éŸ³å¤±è´¥: $e');
    }

    _recordingStartPosition = null;
    recognizedText.value = '';
  }

  void checkCancelMode(Offset globalPosition) {
    if (!isRecording.value || _recordingStartPosition == null) return;
    final deltaY = _recordingStartPosition!.dy - globalPosition.dy;
    isCancelMode.value = deltaY > 50;
  }

  void _startAmplitudeListener() {
    _amplitudeSubscription?.cancel();
    _amplitudeSubscription = _audioRecorder
        .onAmplitudeChanged(const Duration(milliseconds: 100))
        .listen((amplitude) {
          if (isClosed) return;
          final normalized = (amplitude.current + 160) / 160;
          recordingAmplitude.value = normalized.clamp(0.0, 1.0);
        });
  }

  void _stopAmplitudeListener() {
    _amplitudeSubscription?.cancel();
    _amplitudeSubscription = null;
    recordingAmplitude.value = 0.0;
  }

  Future<void> _startSpeechRecognition() async {
    try {
      final available = await _speechToText.initialize(
        onError: (error) {
          logPrint('è¯­éŸ³è¯†åˆ«é”™è¯¯: ${error.errorMsg}');
        },
        onStatus: (status) {
          logPrint('è¯­éŸ³è¯†åˆ«çŠ¶æ€: $status');
        },
      );

      if (available) {
        await _speechToText.listen(
          onResult: (result) {
            final text = _sanitizeText(result.recognizedWords);
            recognizedText.value = text;
            logPrint('è¯­éŸ³è¯†åˆ«: $text');
          },
          localeId: 'zh_CN',
        );
      } else {
        logPrint('è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨');
      }
    } catch (e) {
      logPrint('å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: $e');
    }
  }

  Future<void> _stopSpeechRecognition() async {
    try {
      if (_speechToText.isListening) {
        await _speechToText.stop();
      }
    } catch (e) {
      logPrint('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥: $e');
    }
  }

  String _sanitizeText(String text) {
    if (text.isEmpty) return text;
    final buffer = StringBuffer();
    for (int i = 0; i < text.length; i++) {
      final codeUnit = text.codeUnitAt(i);
      if (codeUnit >= 0xD800 && codeUnit <= 0xDFFF) {
        if (codeUnit <= 0xDBFF && i + 1 < text.length) {
          final nextCodeUnit = text.codeUnitAt(i + 1);
          if (nextCodeUnit >= 0xDC00 && nextCodeUnit <= 0xDFFF) {
            buffer.write(text[i]);
            buffer.write(text[i + 1]);
            i++;
            continue;
          }
        }
        continue;
      }
      if (codeUnit < 32 && codeUnit != 10 && codeUnit != 9) {
        continue;
      }
      buffer.write(text[i]);
    }
    return buffer.toString();
  }

  /// ç‚¹å‡»åŠŸèƒ½åŒºæŒ‰é’®
  Future<void> clickAction(ActionType type) async {
    switch (type) {
      case ActionType.camera:
        await ImagePickerUtil.takePhotoOrFromLibrary(
          imageSource: ImageSourceType.camera,
        );
      case ActionType.photo:
        await ImagePickerUtil.takePhotoOrFromLibrary(
          imageSource: ImageSourceType.gallery,
        );
      case ActionType.file:
        try {
          FilePickerResult? result = await FilePicker.platform.pickFiles(
            type: FileType.any, // æ‰€æœ‰ç±»å‹
            allowMultiple: false, // å•é€‰
          );
          if (result != null && result.files.isNotEmpty) {
            PlatformFile file = result.files.first;
            logPrint('æ–‡ä»¶å: ${file.name}');
            logPrint('æ–‡ä»¶å¤§å°: ${file.size} bytes');
            logPrint('æ–‡ä»¶è·¯å¾„: ${file.path}');
            logPrint('æ–‡ä»¶æ‰©å±•å: ${file.extension}');

            NetUtils.uploadSingleFile(file.path!).then((result) {
              logPrint('result====$result');
            });
          }
        } catch (e) {
          logPrint('é€‰å–é”™è¯¯===$e');
        }
    }
  }

  ///è·å–ç³»ç»Ÿé…ç½®
  void getSystemConfig() {
    NetUtils.get(Apis.systemConfig).then((result) {
      if (result.code == NetCodeHandle.success) {
        var id = result.data?['sys_def_agent'];
        agentId = id.toString();
        getAgentUIConfig(id);
      }
    });
  }

  ///è·å–Aiæ™ºèƒ½å›¾UIé…ç½®
  void getAgentUIConfig(id) {
    NetUtils.get(
      Apis.agentUIConfig,
      queryParameters: {'id': id},
      isLoading: false,
    ).then((result) {
      if (result.code == NetCodeHandle.success) {
        var model = ChatAgentUiConfig.fromJson(result.data ?? {});
        _addAiWelcome(model);
      }
    });
  }


  /// å–æ¶ˆå½“å‰è¿æ¥
  void cancelConnection() {
    _sseSubscription?.cancel();
    _sseSubscription = null;
    isLoading.value = false;
    logPrint('SSE è¿æ¥å·²å–æ¶ˆ');
  }


}

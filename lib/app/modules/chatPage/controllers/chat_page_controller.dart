import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:file_picker/file_picker.dart';
import 'package:flutter_image_compress/flutter_image_compress.dart';
import 'package:lawyer_app/app/common/extension/string_extension.dart';
import 'package:lawyer_app/app/http/apis.dart';
import 'package:lawyer_app/app/http/net/net_utils.dart';
import 'package:lawyer_app/app/http/net/tool/error_handle.dart';
import 'package:lawyer_app/app/modules/chatPage/views/widgets/chat_bottom_panel.dart';
import 'package:lawyer_app/app/utils/object_utils.dart';
import 'package:path_provider/path_provider.dart';

import 'package:chat_bottom_container/chat_bottom_container.dart';
import 'package:flutter/material.dart';
import 'package:get/get.dart';
import 'package:lawyer_app/app/http/net/tool/logger.dart';
import 'package:lawyer_app/app/utils/permission_util.dart';
import 'package:lawyer_app/app/utils/toast_utils.dart';
import 'package:pull_to_refresh_new/pull_to_refresh.dart';
import 'package:record/record.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:uuid/uuid.dart';
import 'package:vibration/vibration.dart';

import '../../../http/net/sse_utils.dart';
import '../../../utils/image_picker_util.dart';
import '../models/chat_agent_ui_config.dart';
import '../models/chat_history_list.dart';
import '../models/ui_message.dart';

enum ChatPanelType { none, keyboard, tool }

class ChatPageController extends GetxController {
  final TextEditingController textController = TextEditingController();
  final FocusNode inputFocusNode = FocusNode();
  final ChatBottomPanelContainerController<ChatPanelType> panelController =
      ChatBottomPanelContainerController<ChatPanelType>();
  final ScrollController scrollController = ScrollController();

  /// æ˜¯å¦ç½‘ç»œè¯·æ±‚ä¸­
  bool isNetRequesting = false;

  final RxList<UiMessage> messages = <UiMessage>[].obs;
  final RxBool hasText = false.obs;
  final RxBool hasVoice = false.obs;
  final RxBool isRecording = false.obs;
  final RxBool isCancelMode = false.obs;
  final RxDouble recordingAmplitude = 0.0.obs;
  final RxString recognizedText = ''.obs;
  ChatPanelType currentPanelType = ChatPanelType.none;

  final AudioRecorder _audioRecorder = AudioRecorder();
  final stt.SpeechToText _speechToText = stt.SpeechToText();
  String? _recordingPath;
  Offset? _recordingStartPosition;
  StreamSubscription<Amplitude>? _amplitudeSubscription;

  ///èŠå¤©æ™ºèƒ½ä½“id
  var agentId = Rx<String?>(null);

  ///èŠå¤©id
  var sessionId = Rx<String?>(null);

  // å½“å‰æ¶ˆæ¯å†…å®¹
  final RxString currentMessage = ''.obs;

  // åŠ è½½çŠ¶æ€
  final RxBool isLoading = false.obs;

  RxList<MessageFileModel> files = <MessageFileModel>[].obs; // æ–‡ä»¶æ•°ç»„
  RxList<MessageImageModel> images = <MessageImageModel>[].obs; // å›¾ç‰‡æ•°ç»„

  // SSE è®¢é˜…
  StreamSubscription<SSEEvent>? _sseSubscription;

  // è¯­éŸ³è¯†åˆ«æ˜¯å¦å¯ç”¨ï¼ˆåä¸ºè®¾å¤‡å¯èƒ½ä¸æ”¯æŒï¼‰
  bool _isSpeechRecognitionAvailable = true;

  // æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
  bool enableThinkingMode = true;

  ///æ˜¯å¦æ˜¾ç¤ºæœªæŸ¥è¯¢åˆ°æ¡ˆä»¶
  RxBool isShowNoCase = false.obs;

  void updatePanelType(ChatPanelType type) {
    final targetPanelType = _toBottomPanel(type);
    final targetFocus = _toHandleFocus(type);

    _scrollToBottom();

    void update() {
      panelController.updatePanelType(
        targetPanelType,
        data: type,
        forceHandleFocus: targetFocus,
      );
    }

    final requiresUnfocusFirst =
        type == ChatPanelType.tool && inputFocusNode.hasFocus;
    if (requiresUnfocusFirst) {
      inputFocusNode.unfocus();
      WidgetsBinding.instance.addPostFrameCallback((_) => update());
    } else {
      update();
    }
  }

  void _handleTextChanged() {
    hasText.value = textController.text.trim().isNotEmpty;
  }

  void handleSendPressed({bool isFocus = true}) {
    final text = textController.text.trim();
    if (text.isEmpty) return;
    _addUserMessage(text);
    textController.clear();
    hasText.value = false;
    if (isFocus) {
      inputFocusNode.requestFocus();
    }
  }

  void handleInputTap() {
    updatePanelType(ChatPanelType.keyboard);
  }

  void handleInputPointerUp() {
    if (inputFocusNode.canRequestFocus && !inputFocusNode.hasFocus) {
      updatePanelType(ChatPanelType.keyboard);
    }
  }

  void handleToolBtnClick() {
    final isToolOpen = currentPanelType == ChatPanelType.tool;
    updatePanelType(isToolOpen ? ChatPanelType.keyboard : ChatPanelType.tool);
  }

  void onPanelTypeChange(ChatBottomPanelType panelType, ChatPanelType? data) {
    switch (panelType) {
      case ChatBottomPanelType.none:
        currentPanelType = ChatPanelType.none;
        break;
      case ChatBottomPanelType.keyboard:
        currentPanelType = ChatPanelType.keyboard;
        break;
      case ChatBottomPanelType.other:
        if (data == null) {
          currentPanelType = ChatPanelType.none;
          break;
        }
        currentPanelType = data;
        break;
    }
  }

  void hidePanel() {
    if (inputFocusNode.hasFocus) {
      inputFocusNode.unfocus();
    }
    if (panelController.currentPanelType != ChatBottomPanelType.none) {
      panelController.updatePanelType(ChatBottomPanelType.none);
    }
  }

  ChatBottomPanelType _toBottomPanel(ChatPanelType type) {
    switch (type) {
      case ChatPanelType.none:
        return ChatBottomPanelType.none;
      case ChatPanelType.keyboard:
        return ChatBottomPanelType.keyboard;
      case ChatPanelType.tool:
        return ChatBottomPanelType.other;
    }
  }

  ChatBottomHandleFocus _toHandleFocus(ChatPanelType type) {
    switch (type) {
      case ChatPanelType.keyboard:
        return ChatBottomHandleFocus.requestFocus;
      case ChatPanelType.tool:
      case ChatPanelType.none:
        return ChatBottomHandleFocus.none;
    }
  }

  ///æ·»åŠ æ¬¢è¿å¼€åœºç™½
  void _addAiWelcome(ChatAgentUiConfig model) {
    messages.add(
      UiMessage(
        id: model.id.toString(),
        text: model.prologue ?? 'æ‚¨å¥½ï¼Œæˆ‘æ˜¯ AI åŠ©æ‰‹ï¼Œéšæ—¶ä¸ºæ‚¨æä¾›æ³•å¾‹ç›¸å…³å’¨è¯¢ã€‚',
        isAi: true,
        isPrologue: true,
        createdAt: DateTime.now(),
      ),
    );
  }

  ///æ·»åŠ å‘é€æ¶ˆæ¯
  Future<void> _addUserMessage(String text) async {
    isShowNoCase.value = false;
    logPrint('ğŸš€ å¼€å§‹å‘é€æ¶ˆæ¯: $text');

    if (ObjectUtils.isEmptyString(agentId.value)) {
      logPrint('âš ï¸ agentId ä¸ºç©º');
      return;
    }
    if (ObjectUtils.isEmptyString(sessionId.value)) {
      logPrint('ğŸ“ åˆ›å»ºä¼šè¯ ID...');
      var result = await NetUtils.post(
        Apis.createChatId,
        params: {'agentId': agentId.value, 'subject': text},
        isLoading: false,
      );
      if (result.code == NetCodeHandle.success) {
        sessionId.value = result.data.toString();
        logPrint('âœ… ä¼šè¯ ID: $sessionId');
      }
    }

    if (!ObjectUtils.isEmptyString(sessionId.value)) {
      logPrint('ğŸ“¤ æ·»åŠ ç”¨æˆ·æ¶ˆæ¯');
      messages.add(
        UiMessage(
          id: 'user-${DateTime.now().microsecondsSinceEpoch}',
          text: text,
          isAi: false,
          images: images.isNotEmpty
              ? images.map((img) => img.copyWith()).toList()
              : null,
          files: files.isNotEmpty
              ? files.map((file) => file.copyWith()).toList()
              : null,
          createdAt: DateTime.now(),
        ),
      );

      // ä½¿ç”¨çœŸå®çš„ SSE è¿æ¥æ›¿ä»£æ¨¡æ‹Ÿå›å¤
      logPrint('ğŸ”„ è°ƒç”¨ _sendMessageWithSSE');
      _sendMessageWithSSE(text, sessionId.value!);
    }
  }

  /// ä½¿ç”¨ SSE å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶ AI å›å¤
  Future<void> _sendMessageWithSSE(String message, String sId) async {
    logPrint('ğŸ¯ _sendMessageWithSSE å¼€å§‹æ‰§è¡Œ');
    logPrint('ğŸ“ message: $message, sessionId: $sId');

    // å–æ¶ˆä¹‹å‰çš„è¿æ¥
    cancelConnection();

    isLoading.value = true;
    currentMessage.value = '';

    // ç”¨äºç´¯ç§¯æ€è€ƒè¿‡ç¨‹å’Œå›å¤å†…å®¹
    String thinkingContent = '';
    String replyContent = '';
    final startTime = DateTime.now();

    // è‡ªåŠ¨æ£€æµ‹åç«¯æ˜¯å¦æ”¯æŒæ€è€ƒæ¨¡å¼
    bool backendSupportsThinking = false;
    bool hasReceivedContent = false;

    // åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ AI æ¶ˆæ¯ç”¨äºæ˜¾ç¤ºå®æ—¶å›å¤
    final aiMessageId = 'ai-${DateTime.now().microsecondsSinceEpoch}';

    // ç«‹å³æ·»åŠ ä¸€ä¸ª AI æ¶ˆæ¯å ä½ï¼ˆtext ä¸ºç©ºï¼ŒèŠå¤©æ°”æ³¡ä¼šæ˜¾ç¤º"æ€è€ƒä¸­..."ï¼‰
    messages.add(
      UiMessage(
        id: aiMessageId,
        text: '', // ç©ºæ–‡æœ¬ï¼Œè®©èŠå¤©æ°”æ³¡ç»„ä»¶æ˜¾ç¤º"æ€è€ƒä¸­..."
        isAi: true,
        createdAt: DateTime.now(),
        isThinkingDone: false,
      ),
    );

    // ç”Ÿæˆå”¯ä¸€çš„è¯·æ±‚ ID
    final requestId = const Uuid().v4();

    List<SSEFileModel> uploadFiles = [];
    if (images.isNotEmpty) {
      for (var e in images) {
        uploadFiles.add(SSEFileModel(name: '', url: e.url ?? ''));
      }
    } else if (files.isNotEmpty) {
      for (var e in files) {
        uploadFiles.add(SSEFileModel(name: e.name ?? '', url: e.url ?? ''));
      }
    }

    // æ¸…ç©ºå›¾ç‰‡å’Œæ–‡ä»¶æ•°ç»„
    images.clear();
    files.clear();

    final request = SSEChatRequest(
      message: message,
      requestId: requestId,
      hisId: sId.toNullInt(),
      files: uploadFiles,
      think: enableThinkingMode, // ä½¿ç”¨é…ç½®é¡¹
    );

    logPrint('å‘é€æ¶ˆæ¯: $message, æ€è€ƒæ¨¡å¼: $enableThinkingMode');

    try {
      _sseSubscription = await SSEUtils().chatStream(
        agentId: agentId.value!,
        request: request,
        onMessage: (data) {
          logPrint('ğŸ“¨ æ”¶åˆ° SSE äº‹ä»¶ - eventType: ${data.eventType}');

          if (data.isOcrResult) {
            logPrint('caseId====${data.ocrCaseId}');
            isShowNoCase.value = true;
          }

          // æ£€æµ‹åç«¯æ˜¯å¦æ”¯æŒæ€è€ƒæ¨¡å¼
          if (data.reasoningContent != null &&
              data.reasoningContent!.isNotEmpty) {
            backendSupportsThinking = true;
            thinkingContent += data.reasoningContent!;
            logPrint('âœ… æ”¶åˆ°æ€è€ƒå†…å®¹: ${data.reasoningContent}');
            logPrint('ğŸ“Š ç´¯ç§¯æ€è€ƒå†…å®¹: $thinkingContent');
          }

          // ç´¯ç§¯å›å¤å†…å®¹
          if (data.content != null && data.content!.isNotEmpty) {
            hasReceivedContent = true;
            replyContent += _sanitizeText(data.content!);
            logPrint('âœ… æ”¶åˆ°å›å¤å†…å®¹: ${data.content}');
            logPrint('ğŸ“Š ç´¯ç§¯å›å¤å†…å®¹: $replyContent');
          }

          // è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼
          // æƒ…å†µ1ï¼šåç«¯æ”¯æŒæ€è€ƒæ¨¡å¼ - æœ‰ reasoningContent
          // æƒ…å†µ2ï¼šåç«¯ä¸æ”¯æŒæ€è€ƒæ¨¡å¼ - åªæœ‰ contentï¼Œå³ä½¿å‰ç«¯å‘é€äº† think: true
          final actualMode = backendSupportsThinking ? 'æ€è€ƒæ¨¡å¼' : 'ç›´æ¥å›å¤æ¨¡å¼';

          // ç§»é™¤"æ€è€ƒä¸­"æ¶ˆæ¯ï¼ˆåªç§»é™¤ä¸€æ¬¡ï¼‰
          messages.removeWhere((e) => e.id == 'think_id');

          // åˆ›å»ºæ›´æ–°çš„æ¶ˆæ¯
          final aiMessage = UiMessage(
            id: aiMessageId,
            text: replyContent, // å›å¤å†…å®¹ï¼Œå¯èƒ½ä¸ºç©ºï¼ˆæ€è€ƒé˜¶æ®µï¼‰æˆ–æœ‰å†…å®¹ï¼ˆç›´æ¥å›å¤ï¼‰
            isAi: true,
            createdAt: DateTime.now(),
            thinkingProcess: thinkingContent.isNotEmpty
                ? thinkingContent
                : null,
            isThinkingDone: false, // æµå¼ä¼ è¾“ä¸­ï¼Œæœªå®Œæˆ
          );

          // æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨è¯¥æ¶ˆæ¯
          final existingIndex = messages.indexWhere((m) => m.id == aiMessageId);
          if (existingIndex != -1) {
            // æ›´æ–°ç°æœ‰æ¶ˆæ¯ - ä½¿ç”¨ replaceRange ç¡®ä¿è§¦å‘å“åº”å¼æ›´æ–°
            messages.replaceRange(existingIndex, existingIndex + 1, [
              aiMessage,
            ]);
            logPrint(
              'ğŸ”„ æ›´æ–°æ¶ˆæ¯ [$actualMode] - æ€è€ƒ: ${thinkingContent.length} å­—ç¬¦, å›å¤: ${replyContent.length} å­—ç¬¦',
            );
          } else {
            // æ·»åŠ æ–°æ¶ˆæ¯
            messages.add(aiMessage);
            logPrint(
              'â• æ·»åŠ æ–°æ¶ˆæ¯ [$actualMode] - æ€è€ƒ: ${thinkingContent.length} å­—ç¬¦, å›å¤: ${replyContent.length} å­—ç¬¦',
            );
          }
        },
        onError: (error) {
          logPrint('SSE é”™è¯¯: $error');
          showToast('è¿æ¥å¤±è´¥: $error');
          isLoading.value = false;

          // æ›´æ–°æ¶ˆæ¯ä¸ºé”™è¯¯çŠ¶æ€
          final index = messages.indexWhere((m) => m.id == aiMessageId);
          if (index != -1) {
            messages[index] = UiMessage(
              id: aiMessageId,
              text: 'æŠ±æ­‰ï¼Œè¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
              isAi: true,
              createdAt: messages[index].createdAt,
            );
          }
        },
        onDone: () {
          // è®¡ç®—æ€è€ƒç”¨æ—¶ï¼ˆç§’ï¼‰
          final thinkingSeconds = DateTime.now()
              .difference(startTime)
              .inSeconds;

          final actualMode = backendSupportsThinking ? 'æ€è€ƒæ¨¡å¼' : 'ç›´æ¥å›å¤æ¨¡å¼';

          logPrint('âœ… æ¶ˆæ¯æ¥æ”¶å®Œæˆ [$actualMode]');
          logPrint(
            'ğŸ“Š æœ€ç»ˆæ€è€ƒè¿‡ç¨‹: $thinkingContent (${thinkingContent.length} å­—ç¬¦)',
          );
          logPrint('ğŸ“Š æœ€ç»ˆå›å¤å†…å®¹: $replyContent (${replyContent.length} å­—ç¬¦)');
          logPrint('â±ï¸ ç”¨æ—¶: $thinkingSeconds ç§’');

          if (replyContent.isEmpty && thinkingContent.isEmpty) {
            logPrint('âš ï¸ è­¦å‘Šï¼šæ²¡æœ‰æ”¶åˆ°ä»»ä½•å†…å®¹ï¼');
          }

          // å¦‚æœåç«¯ä¸æ”¯æŒæ€è€ƒæ¨¡å¼ä½†æ²¡æœ‰æ”¶åˆ°å†…å®¹ï¼Œå¯èƒ½æ˜¯é”™è¯¯
          if (!backendSupportsThinking && !hasReceivedContent) {
            logPrint('âš ï¸ åç«¯å¯èƒ½ä¸æ”¯æŒå½“å‰è¯·æ±‚');
          }

          isLoading.value = false;

          // ç§»é™¤"æ€è€ƒä¸­"æ¶ˆæ¯ï¼ˆç¡®ä¿æ¸…ç†ï¼‰
          messages.removeWhere((e) => e.id == 'think_id');

          // æœ€ç»ˆæ›´æ–°æ¶ˆæ¯ï¼ŒåŒ…å«å®Œæ•´çš„æ€è€ƒè¿‡ç¨‹å’Œç”¨æ—¶
          final index = messages.indexWhere((m) => m.id == aiMessageId);
          if (index != -1) {
            final finalMessage = UiMessage(
              id: aiMessageId,
              text: replyContent.isNotEmpty ? replyContent : 'æœªè¯†åˆ«å‡ºç›¸å…³æ¡ˆä»¶',
              isAi: true,
              createdAt: messages[index].createdAt,
              hasAnimated: true, // æµå¼ä¼ è¾“å·²ç»æ˜¯é€å­—æ˜¾ç¤ºï¼Œä¸éœ€è¦æ‰“å­—åŠ¨ç”»
              thinkingProcess: thinkingContent.isNotEmpty
                  ? thinkingContent
                  : null,
              thinkingSeconds: thinkingSeconds,
              isThinkingDone: true, // æµå¼ä¼ è¾“å®Œæˆ
            );
            // ä½¿ç”¨ replaceRange ç¡®ä¿è§¦å‘å“åº”å¼æ›´æ–°
            messages.replaceRange(index, index + 1, [finalMessage]);
            logPrint('ğŸ¯ æœ€ç»ˆæ¶ˆæ¯å·²æ›´æ–° [$actualMode]');
          } else {
            logPrint('âš ï¸ æœªæ‰¾åˆ°æ¶ˆæ¯ ID: $aiMessageId');
          }
        },
      );
    } catch (e) {
      logPrint('å‘é€æ¶ˆæ¯å¤±è´¥: $e');
      showToast('å‘é€å¤±è´¥: $e');
      isLoading.value = false;

      // æ›´æ–°æ¶ˆæ¯ä¸ºé”™è¯¯çŠ¶æ€
      final index = messages.indexWhere((m) => m.id == aiMessageId);
      if (index != -1) {
        messages[index] = UiMessage(
          id: aiMessageId,
          text: 'æŠ±æ­‰ï¼Œå‘é€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
          isAi: true,
          createdAt: messages[index].createdAt,
        );
      }
    }
  }

  void markMessageAnimated(String id) {
    final index = messages.indexWhere((m) => m.id == id);
    if (index == -1) return;
    final current = messages[index];
    if (current.hasAnimated) return;
    messages[index] = current.copyWith(hasAnimated: true);
  }

  // reverse: true æ¨¡å¼ä¸‹ï¼Œæ»šåŠ¨åˆ°åº•éƒ¨å°±æ˜¯æ»šåŠ¨åˆ° position 0
  void _scrollToBottom({bool animated = true}) {
    if (!scrollController.hasClients) return;
    if (animated) {
      scrollController.animateTo(
        0,
        duration: const Duration(milliseconds: 220),
        curve: Curves.easeOut,
      );
    } else {
      scrollController.jumpTo(0);
    }
  }

  @override
  void onInit() {
    super.onInit();
    textController.addListener(_handleTextChanged);
    _checkSpeechRecognitionAvailability();
    getSystemConfig();

    scrollController.addListener(_scrollListener);
  }

  ///æ»šåŠ¨åŠ è½½æ›´å¤šå†å²èŠå¤©è®°å½•
  void _scrollListener() {
    // åˆ¤æ–­æ˜¯å¦æ»šåŠ¨åˆ°åº•éƒ¨ï¼ˆé˜ˆå€¼ 50ï¼‰
    if (scrollController.position.pixels >=
        scrollController.position.maxScrollExtent - 50) {
      if (isNetRequesting) {
        return;
      }
      getChatContent(sessionId.value, isLoadMore: true);
    }
  }

  /// æ£€æŸ¥è¯­éŸ³è¯†åˆ«æ˜¯å¦å¯ç”¨
  Future<void> _checkSpeechRecognitionAvailability() async {
    try {
      _isSpeechRecognitionAvailable = await _speechToText.initialize(
        onError: (error) {
          logPrint('è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–é”™è¯¯: ${error.errorMsg}');
          _isSpeechRecognitionAvailable = false;
        },
      );

      if (!_isSpeechRecognitionAvailable) {
        logPrint('âš ï¸ è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨ï¼Œå½•éŸ³åŠŸèƒ½å·²ç¦ç”¨');
      } else {
        logPrint('âœ… è¯­éŸ³è¯†åˆ«å¯ç”¨');
      }
    } catch (e) {
      _isSpeechRecognitionAvailable = false;
      logPrint('âš ï¸ è¯­éŸ³è¯†åˆ«æ£€æµ‹å¤±è´¥: $e');
    }
  }

  @override
  void onClose() {
    textController.removeListener(_handleTextChanged);
    _stopAmplitudeListener();
    if (_speechToText.isListening) {
      _speechToText.stop();
    }
    if (isRecording.value) {
      _audioRecorder.stop().catchError((e) {
        logPrint('åœæ­¢å½•éŸ³å¤±è´¥: $e');
        return '';
      });
    }
    textController.dispose();
    inputFocusNode.dispose();
    scrollController.dispose();
    _audioRecorder.dispose();
    if (_recordingPath != null) {
      final file = File(_recordingPath!);
      file.exists().then((exists) {
        if (exists) {
          file.delete().catchError((e) {
            logPrint('åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: $e');
            return file;
          });
        }
      });
    }
    cancelConnection();
    super.onClose();
  }

  Future<void> handleVoicePressed() async {
    // æ£€æŸ¥è¯­éŸ³è¯†åˆ«æ˜¯å¦å¯ç”¨
    if (!_isSpeechRecognitionAvailable) {
      showToast('å½“å‰è®¾å¤‡ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½');
      return;
    }

    bool isAuth = false;
    if (Platform.isIOS) {
      bool isMicAuth = await PermissionUtils.requestMicrophonePermission();
      if (isMicAuth) {
        isAuth = await PermissionUtils.requestSpeechPermission();
      }
    } else {
      isAuth = await PermissionUtils.requestMicrophonePermission();
    }
    if (isAuth) {
      hasVoice.value = !hasVoice.value;
      updatePanelType(
        hasVoice.value ? ChatPanelType.none : ChatPanelType.keyboard,
      );
      if (!hasVoice.value) {
        inputFocusNode.requestFocus();
      }
    }
  }

  Future<void> startRecording(Offset startPosition) async {
    // é˜²æ­¢é‡å¤è§¦å‘
    if (isRecording.value) return;

    // éœ‡åŠ¨åé¦ˆ - ä¸ä½¿ç”¨ awaitï¼Œç›´æ¥è§¦å‘
    if (await Vibration.hasVibrator()) {
      Vibration.vibrate(duration: 50);
    }

    // å…ˆæ˜¾ç¤ºå½•éŸ³ UI
    _recordingStartPosition = startPosition;
    isRecording.value = true;
    isCancelMode.value = false;
    recognizedText.value = '';

    try {
      if (await _audioRecorder.hasPermission()) {
        final directory = await getTemporaryDirectory();
        _recordingPath =
            '${directory.path}/recording_${DateTime.now().millisecondsSinceEpoch}.m4a';

        await _audioRecorder.start(
          const RecordConfig(
            encoder: AudioEncoder.aacLc,
            bitRate: 128000,
            sampleRate: 44100,
          ),
          path: _recordingPath!,
        );

        _startAmplitudeListener();
        _startSpeechRecognition();
      } else {
        isRecording.value = false;
      }
    } catch (e) {
      logPrint('å¼€å§‹å½•éŸ³å¤±è´¥: $e');
      isRecording.value = false;
    }
  }

  Future<void> stopRecording() async {
    if (!isRecording.value) return;

    try {
      final path = await _audioRecorder.stop();
      isRecording.value = false;
      _stopAmplitudeListener();
      await _stopSpeechRecognition();

      if (path != null && !isCancelMode.value) {
        final textToSend = recognizedText.value.trim();
        if (textToSend.isNotEmpty) {
          _addUserMessage(textToSend);
        } else {
          // showToast('æœªè¯†åˆ«åˆ°ä»»ä½•å†…å®¹');
          final file = File(_recordingPath!);
          if (await file.exists()) {
            await file.delete();
          }
        }
      } else if (_recordingPath != null && isCancelMode.value) {
        final file = File(_recordingPath!);
        if (await file.exists()) {
          await file.delete();
        }
      }
    } catch (e) {
      logPrint('åœæ­¢å½•éŸ³å¤±è´¥: $e');
    }

    isCancelMode.value = false;
    recognizedText.value = '';
  }

  Future<void> cancelRecording() async {
    if (!isRecording.value) return;

    try {
      await _audioRecorder.stop();
      isRecording.value = false;
      isCancelMode.value = false;
      _stopAmplitudeListener();
      await _stopSpeechRecognition();

      if (_recordingPath != null) {
        final file = File(_recordingPath!);
        if (await file.exists()) {
          await file.delete();
        }
      }
    } catch (e) {
      logPrint('å–æ¶ˆå½•éŸ³å¤±è´¥: $e');
    }

    _recordingStartPosition = null;
    recognizedText.value = '';
  }

  void checkCancelMode(Offset globalPosition) {
    if (!isRecording.value || _recordingStartPosition == null) return;
    final deltaY = _recordingStartPosition!.dy - globalPosition.dy;
    isCancelMode.value = deltaY > 50;
  }

  void _startAmplitudeListener() {
    _amplitudeSubscription?.cancel();
    _amplitudeSubscription = _audioRecorder
        .onAmplitudeChanged(const Duration(milliseconds: 100))
        .listen((amplitude) {
          if (isClosed) return;
          final normalized = (amplitude.current + 160) / 160;
          recordingAmplitude.value = normalized.clamp(0.0, 1.0);
        });
  }

  void _stopAmplitudeListener() {
    _amplitudeSubscription?.cancel();
    _amplitudeSubscription = null;
    recordingAmplitude.value = 0.0;
  }

  Future<void> _startSpeechRecognition() async {
    if (!_isSpeechRecognitionAvailable) {
      logPrint('âš ï¸ è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨ï¼Œè·³è¿‡');
      return;
    }

    try {
      await _speechToText.listen(
        onResult: (result) {
          final text = _sanitizeText(result.recognizedWords);
          recognizedText.value = text;
          logPrint('è¯­éŸ³è¯†åˆ«: $text');
        },
        localeId: 'zh_CN',
      );
    } catch (e) {
      _isSpeechRecognitionAvailable = false;
      logPrint('âš ï¸ å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: $e');
      showToast('è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥');
    }
  }

  Future<void> _stopSpeechRecognition() async {
    try {
      if (_speechToText.isListening) {
        await _speechToText.stop();
      }
    } catch (e) {
      logPrint('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥: $e');
    }
  }

  String _sanitizeText(String text) {
    if (text.isEmpty) return text;
    final buffer = StringBuffer();
    for (int i = 0; i < text.length; i++) {
      final codeUnit = text.codeUnitAt(i);
      if (codeUnit >= 0xD800 && codeUnit <= 0xDFFF) {
        if (codeUnit <= 0xDBFF && i + 1 < text.length) {
          final nextCodeUnit = text.codeUnitAt(i + 1);
          if (nextCodeUnit >= 0xDC00 && nextCodeUnit <= 0xDFFF) {
            buffer.write(text[i]);
            buffer.write(text[i + 1]);
            i++;
            continue;
          }
        }
        continue;
      }
      if (codeUnit < 32 && codeUnit != 10 && codeUnit != 9) {
        continue;
      }
      buffer.write(text[i]);
    }
    return buffer.toString();
  }

  /// ç‚¹å‡»åŠŸèƒ½åŒºæŒ‰é’®
  Future<void> clickAction(ActionType type) async {
    switch (type) {
      case ActionType.camera:
        if (images.length >= 10) {
          showToast('æœ€å¤§ä¸Šä¼ 10å¼ å›¾ç‰‡');
          return;
        }
        var file = await ImagePickerUtil.takePhotoOrFromLibrary(
          imageSource: ImageSourceType.camera,
        );
        if (file != null) {
          uploadImage([file]);
        }
      case ActionType.photo:
        if (images.length >= 10) {
          showToast('æœ€å¤§ä¸Šä¼ 10å¼ å›¾ç‰‡');
          return;
        }
        var imgFiles = await ImagePickerUtil.takeManyPhotoOrFromLibrary(
          imageSource: ImageSourceType.gallery,
          maxCount: 10 - images.length,
        );
        uploadImage(imgFiles);
      case ActionType.file:
        // if (files.length >= 10) {
        //   showToast('æœ€å¤šä¸Šä¼ 10ä¸ªæ–‡æ¡£');
        //   return;
        // }
        try {
          FilePickerResult? result = await FilePicker.platform.pickFiles(
            type: FileType.any, // æ‰€æœ‰ç±»å‹
            allowMultiple: true, // å…è®¸å¤šé€‰
          );
          if (result != null && result.files.isNotEmpty) {
            for (var file in result.files) {
              // PlatformFile file = result.files.first;
              logPrint('æ–‡ä»¶å: ${file.name}');
              logPrint('æ–‡ä»¶å¤§å°: ${file.size} bytes');
              logPrint('æ–‡ä»¶è·¯å¾„: ${file.path}');
              logPrint('æ–‡ä»¶æ‰©å±•å: ${file.extension}');
              if (file.path != null) {
                images.clear();
                files.add(
                  MessageFileModel(
                    path: file.path,
                    name: file.name,
                    type: file.extension,
                  ),
                );
                NetUtils.uploadSingleFile(file.path!).then((result) {
                  logPrint('result====$result');
                  if (result != null) {
                    // æ‰¾åˆ°å¯¹åº”çš„å›¾ç‰‡
                    final index = files.indexWhere((e) => e.path == file.path);
                    if (index != -1) {
                      // ä½¿ç”¨ copyWith æ›´æ–° url
                      files[index] = files[index].copyWith(url: result);
                      files.refresh(); // åˆ·æ–° UI
                    }
                  }
                });
              }
            }
          }
        } catch (e) {
          logPrint('é€‰å–é”™è¯¯===$e');
        }
    }
  }

  ///ä¸Šä¼ å›¾ç‰‡
  void uploadImage(List<XFile>? imgFiles) {
    imgFiles?.forEach((file) {
      images.add(MessageImageModel(path: file.path));

      NetUtils.uploadSingleImage(file.path)
          .then((result) {
            if (result != null) {
              files.clear();
              // æ‰¾åˆ°å¯¹åº”çš„å›¾ç‰‡
              final index = images.indexWhere((e) => e.path == file.path);
              if (index != -1) {
                // ä½¿ç”¨ copyWith æ›´æ–° url
                images[index] = images[index].copyWith(url: result);
                images.refresh(); // åˆ·æ–° UI
              }
            }
          })
          .catchError((error) {
            logPrint('ä¸Šä¼ å›¾ç‰‡å¤±è´¥: $error');
            // å¯é€‰ï¼šä¸Šä¼ å¤±è´¥æ—¶ç§»é™¤è¯¥å›¾ç‰‡
            images.removeWhere((e) => e.path == file.path);
            images.refresh();
          });
    });
  }

  ///è·å–ç³»ç»Ÿé…ç½®
  void getSystemConfig() {
    NetUtils.get(Apis.systemConfig).then((result) {
      if (result.code == NetCodeHandle.success) {
        var id = result.data?['sys_def_agent'];
        agentId.value = id.toString();
        _loadSessions(id);
      }
    });
  }

  ///è·å–Aiæ™ºèƒ½å›¾UIé…ç½®
  void getAgentUIConfig(aId) {
    NetUtils.get(
      Apis.agentUIConfig,
      queryParameters: {'id': aId},
      isLoading: false,
    ).then((result) {
      if (result.code == NetCodeHandle.success) {
        var model = ChatAgentUiConfig.fromJson(result.data ?? {});
        _addAiWelcome(model);
      }
    });
  }

  ///è·å–æœ€æ–°çš„ä¸€æ¡å¯¹è¯
  Future<void> _loadSessions(aId) async {
    NetUtils.get(
      Apis.getAiHistoryList,
      queryParameters: {'agentId': aId, 'pageNo': 1, 'pageSize': 1},
    ).then((result) {
      if (result.code == NetCodeHandle.success) {
        var list = (result.data['list'] as List)
            .map((e) => ChatHistoryList.fromJson(e))
            .toList();
        if (list.isNotEmpty) {
          var sId = list.first.id;
          getChatContent(sId);
        } else {
          getAgentUIConfig(aId);
        }
      }
    });
  }

  ///è·å–èŠå¤©å†…å®¹
  void getChatContent(sId, {bool isLoadMore = false}) {
    sessionId.value = sId.toString();
    if (!isLoadMore) {
      messages.clear();
    }
    isNetRequesting = true;
    NetUtils.get(
      Apis.getAiChatContentList,
      queryParameters: {
        'hisId': sId,
        'cursor': messages.isEmpty ? sId : messages.first.id,
      },
      isLoading: false,
    ).then((result) {
      if (result.code == NetCodeHandle.success) {
        List datas = result.data as List;
        List<UiMessage> models = [];
        for (var map in datas) {
          var msg = map['message'].toString();
          if (!ObjectUtils.isEmptyString(msg)) {
            var msgMap = json.decode(msg);
            var content = msgMap['content'].toString();
            final finalMessage = UiMessage(
              id: map['id'].toString(),
              text: ObjectUtils.isEmptyString(content) ? 'æœªæŸ¥è¯¢åˆ°æ¡ˆä»¶' : content,
              isAi: msgMap['role'] == 'assistant',
              createdAt: DateTime.fromMillisecondsSinceEpoch(
                msgMap['createTime'].toString().toInt(),
              ),
              hasAnimated: true, // æµå¼ä¼ è¾“å·²ç»æ˜¯é€å­—æ˜¾ç¤ºï¼Œä¸éœ€è¦æ‰“å­—åŠ¨ç”»
              isThinkingDone: true, // æµå¼ä¼ è¾“å®Œæˆ
            );
            models.add(finalMessage);
          }
        }
        if (isLoadMore) {
          messages.value.insertAll(0, models);
        } else {
          messages.value = models;
        }
        isNetRequesting = models.isEmpty;
        messages.refresh();
      } else {
        isNetRequesting = false;
      }
    });
  }

  /// å–æ¶ˆå½“å‰è¿æ¥
  void cancelConnection() {
    _sseSubscription?.cancel();
    _sseSubscription = null;
    isLoading.value = false;
    logPrint('SSE è¿æ¥å·²å–æ¶ˆ');
  }

  /// åˆ·æ–°æœ€åä¸€æ¡ AI å›å¤
  void refreshLastAiMessage() {
    logPrint('ğŸ”„ åˆ·æ–°æœ€åä¸€æ¡ AI å›å¤');

    // 1. æ‰¾åˆ°æœ€åä¸€æ¡ AI æ¶ˆæ¯
    final lastAiIndex = messages.lastIndexWhere((m) => m.isAi && !m.isPrologue);
    if (lastAiIndex == -1) {
      logPrint('âš ï¸ æ²¡æœ‰æ‰¾åˆ° AI æ¶ˆæ¯');
      return;
    }

    // 2. æ‰¾åˆ°è¿™æ¡ AI æ¶ˆæ¯ä¹‹å‰çš„æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    final lastUserIndex = messages.lastIndexWhere(
      (m) => !m.isAi,
      lastAiIndex - 1,
    );

    if (lastUserIndex == -1) {
      logPrint('âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯');
      return;
    }

    final lastUserMessage = messages[lastUserIndex];
    logPrint('ğŸ“ æ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯: ${lastUserMessage.text}');

    // 3. ç§»é™¤æœ€åä¸€æ¡ AI æ¶ˆæ¯
    messages.removeAt(lastAiIndex);
    logPrint('ğŸ—‘ï¸ å·²ç§»é™¤ AI æ¶ˆæ¯');

    // 4. é‡æ–°å‘é€ç”¨æˆ·æ¶ˆæ¯
    final currentSessionId = sessionId.value;
    if (currentSessionId != null && currentSessionId.isNotEmpty) {
      logPrint('ğŸ”„ é‡æ–°å‘é€æ¶ˆæ¯');
      _sendMessageWithSSE(lastUserMessage.text, currentSessionId);
    } else {
      logPrint('âš ï¸ sessionId ä¸ºç©º');
    }
  }

  ///æ–°å»ºå¯¹è¯
  void addNewChat() {}
  
}
